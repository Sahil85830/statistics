{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92a9c1-61b2-4912-95aa-aa9f89d51871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.  What is hypothesis testing in statistics?\n",
    "''' Hypothesis testing in statistics is a method used to make decisions or inferences about a population based on a sample. It involves the following steps:  \n",
    "\n",
    "1. **Formulating Hypotheses**:  \n",
    "   - **Null Hypothesis (H₀)**: Assumes no effect or no difference (e.g., \"The average car price is the same across all regions\").  \n",
    "   - **Alternative Hypothesis (H₁ or Ha)**: Represents a claim to be tested (e.g., \"The average car price differs across regions\").  \n",
    "\n",
    "2. **Selecting a Significance Level (α)**:  \n",
    "   - Common values are 0.05 or 0.01, representing the probability of rejecting H₀ when it is true.  \n",
    "\n",
    "3. **Choosing a Test Statistic**:  \n",
    "   - Depends on data type and hypothesis (e.g., t-test, chi-square test, ANOVA).  \n",
    "\n",
    "4. **Computing the p-value**:  \n",
    "   - The probability of obtaining results at least as extreme as observed, assuming H₀ is true.  \n",
    "\n",
    "5. **Making a Decision**:  \n",
    "   - If **p-value ≤ α**, reject H₀ (evidence supports H₁).  \n",
    "   - If **p-value > α**, fail to reject H₀ (not enough evidence to support H₁).  \n",
    "\n",
    "It helps in making data-driven conclusions in various fields like medicine, business, and social sciences. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13769c4-5039-4b53-b926-c214ca801b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
    "'''The **Null Hypothesis (H₀)** and **Alternative Hypothesis (H₁ or Ha)** are fundamental concepts in hypothesis testing:  \n",
    "\n",
    "1. **Null Hypothesis (H₀)**:  \n",
    "   - Represents the default assumption or status quo.  \n",
    "   - Assumes no effect, no difference, or no relationship in the population.  \n",
    "   - Example: *\"There is no difference in the average selling price of cars across different regions.\"*  \n",
    "\n",
    "2. **Alternative Hypothesis (H₁ or Ha)**:  \n",
    "   - Represents what we are trying to prove.  \n",
    "   - Suggests there is an effect, difference, or relationship.  \n",
    "   - Example: *\"The average selling price of cars differs across different regions.\"*  \n",
    "\n",
    "### **Key Difference**:  \n",
    "- The **null hypothesis** is assumed true unless there is strong statistical evidence against it.  \n",
    "- The **alternative hypothesis** is what we aim to support with data.  \n",
    "- If the **p-value ≤ significance level (α)**, we reject H₀ in favor of H₁. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa7c81-32e8-46e0-aa5a-0106c74f24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. What is the significance level in hypothesis testing, and why is it important?\n",
    "'''The **significance level (α)** in hypothesis testing is the probability of rejecting the **null hypothesis (H₀)** when it is actually true (Type I error). It sets the threshold for statistical significance.  \n",
    "\n",
    "### **Common Values of α:**  \n",
    "- **0.05 (5%)** – Most commonly used.  \n",
    "- **0.01 (1%)** – Used for stricter testing (e.g., medical trials).  \n",
    "- **0.10 (10%)** – Sometimes used in exploratory studies.  \n",
    "\n",
    "### **Why is it Important?**  \n",
    "1. **Controls Type I Error**: Reduces the chance of falsely rejecting H₀.  \n",
    "2. **Determines Decision Criteria**: If **p-value ≤ α**, reject H₀; otherwise, fail to reject H₀.  \n",
    "3. **Balances Accuracy**: A lower α reduces false positives but increases false negatives (Type II error).  \n",
    "\n",
    "Choosing α depends on the study context—higher stakes require lower α. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485bfe2-97bb-4942-a920-b5fe4b865a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What does a P-value represent in hypothesis testing?\n",
    "'''The **P-value** in hypothesis testing represents the probability of obtaining results at least as extreme as the observed data, assuming the **null hypothesis (H₀)** is true.  \n",
    "\n",
    "### **Interpretation of P-value:**  \n",
    "- **Low P-value (≤ α, e.g., 0.05)** → Strong evidence **against** H₀ → **Reject H₀** (supports H₁).  \n",
    "- **High P-value (> α)** → Weak evidence against H₀ → **Fail to reject H₀** (insufficient support for H₁).  \n",
    "\n",
    "### **Example:**  \n",
    "If a test yields **P = 0.03** with **α = 0.05**, we reject H₀, suggesting a significant effect or difference exists.  \n",
    "\n",
    "### **Why is it Important?**  \n",
    "- Helps determine statistical significance.  \n",
    "- Provides a measure of strength of evidence against H₀.  \n",
    "- Guides decision-making in research and experiments. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17610afe-3d9f-4498-845f-4a65c0d3dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. How do you interpret the P-value in hypothesis testing?\n",
    "'''### **Interpreting the P-value in Hypothesis Testing**  \n",
    "\n",
    "The **P-value** indicates the probability of obtaining results as extreme as the observed data, assuming the **null hypothesis (H₀)** is true.  \n",
    "\n",
    "### **Interpretation Guidelines:**  \n",
    "- **P ≤ α (e.g., 0.05)** → **Reject H₀** → Strong evidence against H₀ → Supports the alternative hypothesis (**H₁**).  \n",
    "- **P > α** → **Fail to reject H₀** → Insufficient evidence to support H₁ → The observed result could be due to chance.  \n",
    "\n",
    "### **Example Interpretation:**  \n",
    "- **P = 0.02, α = 0.05** → Reject H₀ → Significant result → Suggests an actual effect.  \n",
    "- **P = 0.08, α = 0.05** → Fail to reject H₀ → Not statistically significant → No strong evidence of an effect.  \n",
    "\n",
    "The **smaller the P-value**, the stronger the evidence against H₀. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bc0b0-bb14-4dda-bf8d-09245aff3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
    "'''### **Type 1 and Type 2 Errors in Hypothesis Testing**  \n",
    "\n",
    "#### **1. Type 1 Error (False Positive)**  \n",
    "- Occurs when we **reject the null hypothesis (H₀) when it is actually true**.  \n",
    "- Represented by the **significance level (α)** (e.g., α = 0.05 means a 5% chance of making this error).  \n",
    "- **Example**: A test incorrectly detects a disease in a healthy person.  \n",
    "\n",
    "#### **2. Type 2 Error (False Negative)**  \n",
    "- Occurs when we **fail to reject the null hypothesis (H₀) when it is actually false**.  \n",
    "- Represented by **β (beta)**, where **power = 1 - β** (higher power reduces Type 2 error).  \n",
    "- **Example**: A test fails to detect a disease in a sick person.  \n",
    "\n",
    "### **Key Difference:**  \n",
    "- **Type 1 Error:** Detects an effect that doesn’t exist (false alarm).  \n",
    "- **Type 2 Error:** Misses a real effect (failure to detect).  \n",
    "\n",
    "Balancing **α** and **β** is crucial—lowering one often increases the other. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfd75e-f88a-4119-8b43-ced524ed5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
    "'''### **One-Tailed vs. Two-Tailed Test in Hypothesis Testing**  \n",
    "\n",
    "#### **1. One-Tailed Test (Directional Test)**  \n",
    "- Tests for an effect in **only one direction** (greater or less than).  \n",
    "- **Null Hypothesis (H₀)**: No difference or effect.  \n",
    "- **Alternative Hypothesis (H₁)**: Specifies a direction (e.g., \"Car prices in Region A are higher than in Region B\").  \n",
    "- **Example**:  \n",
    "  - H₀: The average fuel efficiency of a new car model is **≤ 20 km/l**.  \n",
    "  - H₁: The average fuel efficiency is **> 20 km/l**.  \n",
    "- **Used When**: Prior knowledge or theory suggests a specific direction.  \n",
    "\n",
    "#### **2. Two-Tailed Test (Non-Directional Test)**  \n",
    "- Tests for an effect in **both directions** (higher or lower).  \n",
    "- **Null Hypothesis (H₀)**: No difference or effect.  \n",
    "- **Alternative Hypothesis (H₁)**: Any difference, regardless of direction (e.g., \"Car prices in Region A are different from Region B\").  \n",
    "- **Example**:  \n",
    "  - H₀: The average fuel efficiency is **20 km/l**.  \n",
    "  - H₁: The average fuel efficiency is **not 20 km/l**.  \n",
    "- **Used When**: No prior expectation of the effect’s direction.  \n",
    "\n",
    "### **Key Difference:**  \n",
    "- **One-Tailed**: Tests for an increase **or** decrease.  \n",
    "- **Two-Tailed**: Tests for **any** difference, in either direction.  \n",
    "\n",
    "Choosing the right test depends on the research question! '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf99200-69cf-45fe-8bd2-35d3fc2a173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.  What is the Z-test, and when is it used in hypothesis testing?\n",
    "'''### **Z-Test in Hypothesis Testing**  \n",
    "\n",
    "A **Z-test** is a statistical test used to determine whether there is a significant difference between sample and population means or between two samples when the population variance is known. It follows the **standard normal distribution (Z-distribution).**  \n",
    "\n",
    "### **When is the Z-Test Used?**  \n",
    "1. **Large Sample Size (n ≥ 30)**: Central Limit Theorem ensures normality.  \n",
    "2. **Known Population Variance (σ²)**: Unlike the t-test, where variance is estimated.  \n",
    "3. **Normally Distributed Data**: Especially for small samples.  \n",
    "\n",
    "### **Types of Z-Tests:**  \n",
    "1. **One-Sample Z-Test**: Compares a sample mean to a known population mean.  \n",
    "2. **Two-Sample Z-Test**: Compares means of two independent samples.  \n",
    "3. **Proportion Z-Test**: Compares proportions of two groups.  \n",
    "\n",
    "### **Example:**  \n",
    "A car manufacturer claims its cars have an average mileage of **15 km/l**. A sample of 50 cars shows an average of **14.5 km/l** with a known population standard deviation of **1.2 km/l**. A Z-test can check if the difference is statistically significant.  \n",
    " **Z-test is best for large samples with known variance!** '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166118da-08f4-478b-95cb-6352da4b20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
    "''' Z score X minus mu divided by sigma  \n",
    "\n",
    "For a sample mean Z equals X bar minus mu divided by sigma divided by square root of n  \n",
    "\n",
    "X is individual data point  \n",
    "X bar is sample mean  \n",
    "Mu is population mean  \n",
    "Sigma is population standard deviation  \n",
    "n is sample size  \n",
    "\n",
    "Higher absolute Z score means data point is farther from the mean  \n",
    "Z greater than zero value is above the mean  \n",
    "Z less than zero value is below the mean  \n",
    "Z equals zero value is exactly the mean  \n",
    "\n",
    "In hypothesis testing compare Z score with critical values example plus minus one point nine six for ninety five percent confidence  \n",
    "\n",
    "Example calculation  \n",
    "Population mean is twenty five thousand  \n",
    "Sample mean is twenty six thousand five hundred  \n",
    "Sample size is forty  \n",
    "Population standard deviation is three thousand  \n",
    "\n",
    "Z equals twenty six thousand five hundred minus twenty five thousand divided by three thousand divided by square root of forty  \n",
    "\n",
    "Z equals one thousand five hundred divided by four hundred seventy four point three four  \n",
    "\n",
    "Z approximately equals three point one six  \n",
    "\n",
    "Since Z equals three point one six exceeds one point nine six for ninety five percent confidence we reject the null hypothesis suggesting a significant difference.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7fc21-aa46-4d78-a28e-745c374d0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
    "'''T distribution is a probability distribution used in hypothesis testing when the sample size is small or the population standard deviation is unknown  \n",
    "\n",
    "Use T distribution instead of normal distribution when  \n",
    "Sample size is less than thirty  \n",
    "Population standard deviation is unknown  \n",
    "Data is approximately normally distributed  \n",
    "\n",
    "T distribution has heavier tails than normal distribution meaning more variability in smaller samples  \n",
    "\n",
    "As sample size increases T distribution approaches normal distribution.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bc154-6b4a-4a6b-92dd-a6611735e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.What is the difference between a Z-test and a T-test?\n",
    "'''Z test is used when sample size is large and population standard deviation is known  \n",
    "\n",
    "T test is used when sample size is small and population standard deviation is unknown  \n",
    "\n",
    "Z test follows normal distribution while T test follows T distribution with heavier tails  \n",
    "\n",
    "T test is more appropriate for small samples since it accounts for additional variability.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002c045-cdf3-45a0-8900-c1783079824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. What is the T-test, and how is it used in hypothesis testing?'''\n",
    "'''T test is a statistical test used to compare means of a sample and a population or two samples when the population standard deviation is unknown.  \n",
    "\n",
    "Types of T test, One sample T test compares sample mean to a known population mean. Independent two sample T test compares means of two independent groups. Paired T test compares means of the same group before and after a treatment.  \n",
    "\n",
    "Formula for T test, T equals X bar minus mu divided by S divided by square root of n.  \n",
    "\n",
    "Where, X bar is sample mean, Mu is population mean, S is sample standard deviation, n is sample size.  \n",
    "\n",
    "Compare T value with critical T value from T table based on significance level and degrees of freedom to determine statistical significance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8116e-df21-4ed9-899a-60c72e4ec152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
    "'''Z test and T test are both used to compare sample means and test hypotheses about population parameters.  \n",
    "\n",
    "Z test is used when the sample size is large and population standard deviation is known. T test is used when the sample size is small and population standard deviation is unknown.  \n",
    "\n",
    "Both tests assume data is approximately normally distributed. T test accounts for more variability in small samples due to its heavier tails.  \n",
    "\n",
    "As sample size increases, T distribution approaches normal distribution, making Z test and T test results similar for large samples.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7972fc8-e5d1-4091-9b33-862d14816fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. What is a confidence interval, and how is it used to interpret statistical results?\n",
    "'''A confidence interval is a range of values used to estimate a population parameter with a certain level of confidence.  \n",
    "\n",
    "It is calculated as, Confidence interval equals sample statistic plus minus critical value multiplied by standard error.  \n",
    "\n",
    "Where, Sample statistic is sample mean or proportion. Critical value is based on confidence level from Z or T table. Standard error is standard deviation divided by square root of sample size.  \n",
    "\n",
    "A confidence interval of 95 percent means that if the same study is repeated many times, 95 percent of the calculated intervals will contain the true population parameter.  \n",
    "\n",
    "A wider confidence interval indicates more uncertainty, while a narrower interval suggests higher precision.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f650f-1c7c-470a-b993-98ad432c96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. What is the margin of error, and how does it affect the confidence interval?\n",
    "'''Margin of error is the maximum expected difference between the sample statistic and the true population parameter.  \n",
    "\n",
    "It is calculated as, Margin of error equals critical value multiplied by standard error.  \n",
    "\n",
    "Where, Critical value is from Z or T table based on confidence level. Standard error is standard deviation divided by square root of sample size.  \n",
    "\n",
    "A larger margin of error results in a wider confidence interval, indicating more uncertainty. A smaller margin of error results in a narrower confidence interval, indicating higher precision.  \n",
    "\n",
    "Margin of error decreases with a larger sample size and lower variability in data.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370749ae-9c8d-4ba6-ad73-6b014acf31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
    "'''Bayes' Theorem is used to update probabilities based on new evidence.  \n",
    "\n",
    "Formula, Posterior probability equals Prior probability multiplied by Likelihood divided by Evidence.  \n",
    "\n",
    "Where, Prior probability is initial belief about an event. Likelihood is probability of evidence given the event. Evidence is total probability of observed data.  \n",
    "\n",
    "Significance, It helps in decision-making by updating probabilities with new information. It is widely used in machine learning, medical diagnosis, spam filtering, and risk assessment. It provides a probabilistic framework for inference.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b69fd-74d5-4d2b-b27f-e4513c368cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. What is the Chi-square distribution, and when is it used?\n",
    "'''Chi square distribution is a probability distribution used in statistical tests involving categorical data and variance estimation.  \n",
    "\n",
    "It is used when testing the independence of two categorical variables in a contingency table, called the Chi square test for independence. It is also used to test if an observed frequency distribution matches an expected distribution, called the Chi square goodness of fit test. It is used in variance estimation for normally distributed populations.  \n",
    "\n",
    "Chi square distribution is always positive and skewed right, but it becomes more symmetric as degrees of freedom increase.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106a956-22a4-461b-b087-b34c260baf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. What is the Chi-square goodness of fit test, and how is it applied?\n",
    "'''Chi square goodness of fit test checks if an observed frequency distribution matches an expected distribution.  \n",
    "\n",
    "Formula, Chi square equals sum of observed frequency minus expected frequency squared divided by expected frequency.  \n",
    "\n",
    "Where, Observed frequency is actual data count, Expected frequency is theoretical count based on assumption.  \n",
    "\n",
    "Steps, Define null hypothesis stating that observed and expected distributions are the same. Calculate expected frequencies based on assumption. Compute Chi square statistic using the formula. Compare Chi square value with critical value from Chi square table based on degrees of freedom and significance level. Reject null hypothesis if Chi square value is greater than critical value.  \n",
    "\n",
    "Application, Used in genetics, market research, and quality control to test distribution assumptions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65962a-6042-4957-9aa9-d2e6ddc811b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. What is the F-distribution, and when is it used in hypothesis testing?\n",
    "'''F distribution is a probability distribution used to compare variances of two populations and in analysis of variance ANOVA.  \n",
    "\n",
    "It is used when testing if two population variances are equal, called the F test for variance comparison. It is also used in ANOVA to compare means of multiple groups by analyzing variance. It is applied in regression analysis to test overall model significance.  \n",
    "\n",
    "F distribution is always positive and right skewed. Its shape depends on two degrees of freedom, one for numerator and one for denominator.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70cc57-01f3-412f-90c9-3cbeee6c35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. What is an ANOVA test, and what are its assumptions?\n",
    "'''ANOVA test, Analysis of Variance, is a statistical test used to compare means of three or more groups to determine if there is a significant difference.  \n",
    "\n",
    "Assumptions, The data follows a normal distribution within each group. The variances of all groups are equal, called homogeneity of variance. The observations are independent within and across groups.  \n",
    "\n",
    "If assumptions hold, ANOVA determines if at least one group mean is different, but it does not specify which group differs. Post hoc tests like Tukey test are used for pairwise comparisons.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81f435-f230-46ad-bbf6-52b97ff2c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. What are the different types of ANOVA tests?\n",
    "'''The main types of ANOVA (Analysis of Variance) tests are:\n",
    "\n",
    "1. **One-Way ANOVA**: Used to compare means across more than two groups based on one independent variable.\n",
    "\n",
    "2. **Two-Way ANOVA**: Assesses the effect of two independent variables on a dependent variable, and can also examine interaction effects between the two factors.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Used when the same subjects are measured multiple times under different conditions.\n",
    "\n",
    "4. **Multivariate Analysis of Variance (MANOVA)**: Extends ANOVA to multiple dependent variables.\n",
    "\n",
    "5. **Analysis of Covariance (ANCOVA)**: Combines ANOVA and regression to examine the effect of one or more categorical independent variables on a continuous dependent variable, adjusting for covariates.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba37ca5-f298-4197-804c-0094b3cd78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22. What is the F-test, and how does it relate to hypothesis testing?\n",
    "'''The **F-test** is used to compare two variances or to test the overall significance of a model. In hypothesis testing, it is commonly used in the context of **ANOVA** and **regression analysis**.\n",
    "\n",
    "1. **In ANOVA**: The F-test compares the variance between group means to the variance within the groups. If the ratio (F-statistic) is large, it suggests that the means of the groups are significantly different.\n",
    "\n",
    "2. **In Regression**: The F-test evaluates whether at least one of the predictor variables is significantly related to the dependent variable by testing the null hypothesis that all regression coefficients are zero.\n",
    "\n",
    "The F-test follows this process:\n",
    "- **Null hypothesis (H₀)**: Assumes no effect or no difference (e.g., no relationship between variables).\n",
    "- **Alternative hypothesis (H₁)**: Suggests a significant effect or difference.\n",
    "\n",
    "A large F-statistic leads to rejecting the null hypothesis, indicating a significant difference or effect.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96562e-d945-43ec-973a-cf702f48abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                        #PRACTICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6c17f-98f0-4a36-96b3-08e2b110df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "sample_data = [55, 58, 60, 62, 54, 59, 61, 63, 64, 58]  # Sample of observations\n",
    "population_mean = 60  # Known population mean\n",
    "population_std = 5  # Known population standard deviation\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Compute the Z-statistic\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Compute the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d52db6-2548-457a-b07f-3531b0e47b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulating random data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 10  # Known population standard deviation\n",
    "sample_size = 100  # Sample size\n",
    "\n",
    "# Generate random data from a normal distribution with the known population parameters\n",
    "sample_data = np.random.normal(loc=population_mean, scale=population_std, size=sample_size)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Perform Z-test (one-sample)\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Calculate the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee133016-7e0c-49ed-8a59-44845127f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "sample_data = [48, 50, 52, 49, 51, 50, 48, 50, 49, 52]  # Sample of observations\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 5  # Known population standard deviation\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Compute the Z-statistic\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Compute the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9303fab-5c3e-41f3-9c5d-3a8f45c9b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "sample_data = [48, 50, 52, 49, 51, 50, 48, 50, 49, 52]  # Sample of observations\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 5  # Known population standard deviation\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Compute the Z-statistic\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Compute the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Visualization of the normal distribution and decision regions\n",
    "alpha = 0.05  # Significance level\n",
    "z_critical = stats.norm.ppf(1 - alpha / 2)  # Critical value for two-tailed test\n",
    "\n",
    "# Create a range of values for plotting the standard normal distribution\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = stats.norm.pdf(x)\n",
    "\n",
    "# Plot the normal distribution curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, label=\"Standard Normal Distribution\", color='b')\n",
    "\n",
    "# Shade the critical regions (alpha/2 on both tails)\n",
    "plt.fill_between(x, y, 0, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.5, label='Critical Region')\n",
    "\n",
    "# Mark the Z-statistic on the plot\n",
    "plt.axvline(z_statistic, color='green', linestyle='dashed', label=f\"Z-Statistic: {z_statistic:.2f}\")\n",
    "plt.axvline(-z_statistic, color='green', linestyle='dashed')\n",
    "\n",
    "# Highlight the critical Z values (± z_critical)\n",
    "plt.axvline(z_critical, color='orange', linestyle='dashed', label=f\"Critical Z: ±{z_critical:.2f}\")\n",
    "plt.axvline(-z_critical, color='orange', linestyle='dashed')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Two-Tailed Z-Test: Decision Region Visualization\")\n",
    "plt.xlabel(\"Z-Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f01c6a-c933-4771-b21a-dd2aeafe3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Function to calculate and visualize Type I and Type II errors\n",
    "def visualize_errors(sample_size, population_mean, population_std, alternative_mean, alpha=0.05):\n",
    "    # Generate values for the standard normal distribution under the null hypothesis\n",
    "    x = np.linspace(population_mean - 4 * population_std, population_mean + 4 * population_std, 1000)\n",
    "    null_dist = stats.norm.pdf(x, population_mean, population_std / np.sqrt(sample_size))  # Under null hypothesis\n",
    "\n",
    "    # Generate values for the sampling distribution under the alternative hypothesis\n",
    "    alt_dist = stats.norm.pdf(x, alternative_mean, population_std / np.sqrt(sample_size))  # Under alternative hypothesis\n",
    "\n",
    "    # Critical value for two-tailed test\n",
    "    z_critical = stats.norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    # Type I Error (rejecting the null when it's true) is the area in the rejection region under the null hypothesis\n",
    "    type_1_error_area = stats.norm.cdf(-z_critical, population_mean, population_std / np.sqrt(sample_size)) + \\\n",
    "                         (1 - stats.norm.cdf(z_critical, population_mean, population_std / np.sqrt(sample_size)))\n",
    "\n",
    "    # Type II Error (failing to reject the null when the alternative is true) is the area under the alternative curve\n",
    "    # that does not fall into the rejection region\n",
    "    type_2_error_area = stats.norm.cdf(z_critical, alternative_mean, population_std / np.sqrt(sample_size)) - \\\n",
    "                        stats.norm.cdf(-z_critical, alternative_mean, population_std / np.sqrt(sample_size))\n",
    "\n",
    "    # Plotting the distributions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the null distribution\n",
    "    plt.plot(x, null_dist, label='Null Hypothesis Distribution (H₀)', color='blue')\n",
    "    \n",
    "    # Plot the alternative distribution\n",
    "    plt.plot(x, alt_dist, label='Alternative Hypothesis Distribution (H₁)', color='green')\n",
    "\n",
    "    # Shade the critical regions for Type I error\n",
    "    plt.fill_between(x, null_dist, 0, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.5, label='Critical Region (Rejection Region)')\n",
    "    \n",
    "    # Shade the Type II error area under the alternative distribution (failure to reject H₀)\n",
    "    plt.fill_between(x, alt_dist, 0, where=(x > -z_critical) & (x < z_critical), color='yellow', alpha=0.5, label='Type II Error Region')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f\"Visualization of Type I and Type II Errors\\nType I Error Area = {type_1_error_area:.4f}, Type II Error Area = {type_2_error_area:.4f}\")\n",
    "    plt.xlabel('Z-Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Return the error areas\n",
    "    return type_1_error_area, type_2_error_area\n",
    "\n",
    "# Example usage\n",
    "sample_size = 30  # Sample size\n",
    "population_mean = 50  # Null hypothesis population mean\n",
    "population_std = 5  # Population standard deviation\n",
    "alternative_mean = 52  # Alternative hypothesis mean (effect size)\n",
    "\n",
    "# Call the function and visualize the errors\n",
    "type_1_error, type_2_error = visualize_errors(sample_size, population_mean, population_std, alternative_mean)\n",
    "\n",
    "print(f\"Type I Error (α): {type_1_error:.4f}\")\n",
    "print(f\"Type II Error (β): {type_2_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036f203-4abe-4d96-8487-babe2c883532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Write a Python program to perform an independent T-test and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for two groups\n",
    "group1 = [23, 25, 29, 31, 22, 27, 30, 29, 28, 26]  # Group 1 data\n",
    "group2 = [34, 36, 33, 38, 35, 37, 39, 32, 33, 34]  # Group 2 data\n",
    "\n",
    "# Perform the independent T-test\n",
    "t_statistic, p_value = stats.ttest_ind(group1, group2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the two groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two groups.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122f2a7-6506-479c-ac28-3fb46eca28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.  Perform a paired sample T-test using Python and visualize the comparison results.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Example data: Measurements before and after some intervention (paired samples)\n",
    "before = [85, 88, 90, 87, 86, 91, 89, 92, 85, 88]  # Measurements before intervention\n",
    "after = [82, 84, 89, 85, 83, 88, 87, 90, 83, 86]   # Measurements after intervention\n",
    "\n",
    "# Perform the paired sample T-test\n",
    "t_statistic, p_value = stats.ttest_rel(before, after)\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between before and after intervention.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between before and after intervention.\")\n",
    "\n",
    "# Visualization: Plotting the before and after values\n",
    "x = np.arange(len(before))\n",
    "\n",
    "# Plotting before and after values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, before, 'o-', label=\"Before Intervention\", color='blue')\n",
    "plt.plot(x, after, 'o-', label=\"After Intervention\", color='green')\n",
    "\n",
    "# Adding a horizontal line at y=0 to emphasize the differences\n",
    "plt.axhline(0, color='black', linewidth=1)\n",
    "\n",
    "# Highlight the differences\n",
    "for i in range(len(before)):\n",
    "    plt.plot([x[i], x[i]], [before[i], after[i]], color='gray', alpha=0.7)\n",
    "\n",
    "plt.title(\"Paired Sample T-Test: Before vs After Intervention\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638699e-bf50-4fff-8aa3-559593aee5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Simulate data and perform both Z-test and T-test, then compare the results using Python.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Step 1: Simulate Data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Simulate sample data (e.g., sample of 30 observations from a population)\n",
    "sample_data = np.random.normal(loc=50, scale=10, size=30)  # mean=50, std=10, size=30\n",
    "\n",
    "# Known population parameters\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 10   # Known population standard deviation\n",
    "\n",
    "# Step 2: Perform the Z-test (using the known population mean and std)\n",
    "sample_mean = np.mean(sample_data)\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Z-statistic formula: (sample_mean - population_mean) / (population_std / sqrt(sample_size))\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# p-value for two-tailed Z-test\n",
    "p_value_z = 2 * (1 - stats.norm.cdf(abs(z_statistic)))  # Two-tailed test\n",
    "\n",
    "# Step 3: Perform the T-test (using sample data)\n",
    "t_statistic, p_value_t = stats.ttest_1samp(sample_data, population_mean)\n",
    "\n",
    "# Step 4: Output results and compare\n",
    "\n",
    "print(f\"Z-test: Z-statistic = {z_statistic:.3f}, P-value = {p_value_z:.4f}\")\n",
    "print(f\"T-test: T-statistic = {t_statistic:.3f}, P-value = {p_value_t:.4f}\")\n",
    "\n",
    "# Interpretation based on a significance level of 0.05\n",
    "alpha = 0.05\n",
    "\n",
    "# Z-test interpretation\n",
    "if p_value_z < alpha:\n",
    "    print(\"Z-test: Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Z-test: Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n",
    "\n",
    "# T-test interpretation\n",
    "if p_value_t < alpha:\n",
    "    print(\"T-test: Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"T-test: Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9058a48-87ee-421e-b19b-de65a0c255ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Function to calculate the confidence interval for a sample mean\n",
    "def calculate_confidence_interval(sample_data, confidence_level=0.95):\n",
    "    # Sample statistics\n",
    "    sample_mean = np.mean(sample_data)\n",
    "    sample_std = np.std(sample_data, ddof=1)  # Sample standard deviation (Bessel's correction)\n",
    "    sample_size = len(sample_data)\n",
    "    \n",
    "    # Standard Error (SE)\n",
    "    se = sample_std / np.sqrt(sample_size)\n",
    "    \n",
    "    # Critical value for the confidence level\n",
    "    alpha = 1 - confidence_level\n",
    "    critical_value = stats.t.ppf(1 - alpha/2, df=sample_size-1)  # Using T-distribution for small samples\n",
    "    \n",
    "    # Margin of error\n",
    "    margin_of_error = critical_value * se\n",
    "    \n",
    "    # Confidence interval\n",
    "    ci_lower = sample_mean - margin_of_error\n",
    "    ci_upper = sample_mean + margin_of_error\n",
    "    \n",
    "    return sample_mean, ci_lower, ci_upper\n",
    "\n",
    "# Example usage with simulated data\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Generate sample data\n",
    "\n",
    "sample_mean, ci_lower, ci_upper = calculate_confidence_interval(sample_data, confidence_level=0.95)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755784d-5fe0-41db-a5c1-972305e849bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Write a Python program to calculate the margin of error for a given confidence level using sample data.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Function to calculate margin of error for a given confidence level\n",
    "def calculate_margin_of_error(sample_data, confidence_level=0.95):\n",
    "    # Sample statistics\n",
    "    sample_mean = np.mean(sample_data)\n",
    "    sample_std = np.std(sample_data, ddof=1)  # Sample standard deviation (Bessel's correction)\n",
    "    sample_size = len(sample_data)\n",
    "    \n",
    "    # Standard Error (SE)\n",
    "    se = sample_std / np.sqrt(sample_size)\n",
    "    \n",
    "    # Critical value for the confidence level\n",
    "    alpha = 1 - confidence_level\n",
    "    critical_value = stats.t.ppf(1 - alpha/2, df=sample_size-1)  # Using T-distribution for small samples\n",
    "    \n",
    "    # Margin of error\n",
    "    margin_of_error = critical_value * se\n",
    "    \n",
    "    return margin_of_error\n",
    "\n",
    "# Example usage with simulated data\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Generate sample data\n",
    "\n",
    "margin_of_error = calculate_margin_of_error(sample_data, confidence_level=0.95)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Margin of Error at 95% confidence level: {margin_of_error:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764ef75-1ca8-43e0-afbd-4c24ebcf155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.  Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process.\n",
    "\n",
    "# Define the Bayesian Inference function\n",
    "def bayesian_inference(prior, likelihood, evidence):\n",
    "    \"\"\"\n",
    "    Perform Bayesian Inference using Bayes' Theorem to calculate the posterior probability.\n",
    "    \n",
    "    :param prior: P(H) - Prior probability of the hypothesis (initial belief)\n",
    "    :param likelihood: P(E | H) - Likelihood of the evidence given the hypothesis\n",
    "    :param evidence: P(E) - Total probability of the evidence\n",
    "    :return: Posterior probability P(H | E)\n",
    "    \"\"\"\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    return posterior\n",
    "\n",
    "# Example: Medical Test Scenario\n",
    "# Prior Probability (P(H)): Probability of having the disease (0.01 = 1% chance)\n",
    "prior = 0.01\n",
    "\n",
    "# Likelihood (P(E | H)): Probability of testing positive if you have the disease (test sensitivity)\n",
    "likelihood = 0.95  # 95% sensitivity\n",
    "\n",
    "# Evidence (P(E)): Total probability of testing positive (combination of true positives and false positives)\n",
    "# We need to calculate this as:\n",
    "# P(E) = P(E | H) * P(H) + P(E | not H) * P(not H)\n",
    "# P(E | not H) is the false positive rate (probability of testing positive when not having the disease)\n",
    "false_positive_rate = 0.05  # 5% false positive rate\n",
    "not_having_disease = 1 - prior  # Probability of not having the disease\n",
    "\n",
    "evidence = (likelihood * prior) + (false_positive_rate * not_having_disease)\n",
    "\n",
    "# Perform Bayesian Inference\n",
    "posterior = bayesian_inference(prior, likelihood, evidence)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Posterior Probability (P(H | E)): {posterior:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcdace4-8d16-4c25-8a8c-e2afc85a3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. Perform a Chi-square test for independence between two categorical variables in Python.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Example data: Contingency Table for two categorical variables (e.g., gender and preference for a product)\n",
    "# Rows represent gender (Male, Female), and columns represent product preference (Product A, Product B)\n",
    "data = np.array([[30, 10],   # 30 males prefer Product A, 10 males prefer Product B\n",
    "                 [20, 20]])  # 20 females prefer Product A, 20 females prefer Product B\n",
    "\n",
    "# Convert the data into a DataFrame for better visualization\n",
    "df = pd.DataFrame(data, columns=['Product A', 'Product B'], index=['Male', 'Female'])\n",
    "print(\"Contingency Table:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Perform the Chi-Square Test for Independence\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Step 3: Output the results\n",
    "print(f\"\\nChi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Step 4: Interpretation of Results\n",
    "alpha = 0.05  # Significance level\n",
    "if p_val < alpha:\n",
    "    print(\"\\nConclusion: Reject the null hypothesis. The two variables are dependent.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Fail to reject the null hypothesis. The two variables are independent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb00a9d-f5c1-4ddc-bb06-96fd72a648d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. Write a Python program to calculate the expected frequencies for a Chi-square test based on observed  data.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate expected frequencies for a Chi-Square test\n",
    "def calculate_expected_frequencies(observed_data):\n",
    "    # Calculate the row sums, column sums, and total sum\n",
    "    row_sums = np.sum(observed_data, axis=1)  # Sum of rows\n",
    "    col_sums = np.sum(observed_data, axis=0)  # Sum of columns\n",
    "    total_sum = np.sum(observed_data)  # Grand total\n",
    "\n",
    "    # Calculate the expected frequencies for each cell\n",
    "    expected_frequencies = np.outer(row_sums, col_sums) / total_sum\n",
    "\n",
    "    return expected_frequencies\n",
    "\n",
    "# Example data: Contingency Table for two categorical variables\n",
    "# Rows represent gender (Male, Female), and columns represent product preference (Product A, Product B)\n",
    "observed_data = np.array([[30, 10],   # 30 males prefer Product A, 10 males prefer Product B\n",
    "                          [20, 20]])  # 20 females prefer Product A, 20 females prefer Product B\n",
    "\n",
    "# Calculate the expected frequencies\n",
    "expected_frequencies = calculate_expected_frequencies(observed_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Observed Data:\")\n",
    "print(observed_data)\n",
    "\n",
    "print(\"\\nExpected Frequencies:\")\n",
    "print(expected_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b91b60-8e0c-4cf2-b820-d16fe7f76f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Example data: Observed frequencies of outcomes from rolling a fair die (6 faces)\n",
    "observed_data = np.array([12, 15, 17, 10, 14, 12])  # Observed frequencies for each face\n",
    "\n",
    "# Expected frequencies: For a fair die, we expect each face to appear equally often\n",
    "# Since there are 6 faces, the expected frequency for each face is the same\n",
    "expected_data = np.array([sum(observed_data) / 6] * 6)\n",
    "\n",
    "# Perform the Chi-Square Goodness-of-Fit Test\n",
    "chi2_stat, p_val = chisquare(observed_data, expected_data)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_val < alpha:\n",
    "    print(\"\\nConclusion: Reject the null hypothesis. The observed data does not follow the expected distribution.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Fail to reject the null hypothesis. The observed data follows the expected distribution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c0ec6-9c96-4f8f-8236-e3f25d4c96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Set the degrees of freedom for different distributions\n",
    "dfs = [1, 2, 5, 10, 20]  # Degrees of freedom\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Generate and plot Chi-square distributions for each degree of freedom\n",
    "x = np.linspace(0, 30, 1000)  # Range of values for x-axis\n",
    "\n",
    "for df in dfs:\n",
    "    # Generate the probability density function (PDF) for each degree of freedom\n",
    "    y = chi2.pdf(x, df)\n",
    "    plt.plot(x, y, label=f'df = {df}')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Chi-square Distribution for Different Degrees of Freedom')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend(title=\"Degrees of Freedom\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5a7b2-18d6-4492-bdef-88301c3e600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. Implement an F-test using Python to compare the variances of two random samples.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Generate two random samples\n",
    "np.random.seed(0)  # For reproducibility\n",
    "sample1 = np.random.normal(50, 10, 100)  # Mean = 50, Std = 10, Size = 100\n",
    "sample2 = np.random.normal(55, 15, 100)  # Mean = 55, Std = 15, Size = 100\n",
    "\n",
    "# Calculate the sample variances\n",
    "var1 = np.var(sample1, ddof=1)  # Sample variance for sample1\n",
    "var2 = np.var(sample2, ddof=1)  # Sample variance for sample2\n",
    "\n",
    "# Calculate the F-statistic (larger variance first)\n",
    "f_statistic = var1 / var2 if var1 > var2 else var2 / var1\n",
    "\n",
    "# Degrees of freedom for each sample\n",
    "df1 = len(sample1) - 1  # Degrees of freedom for sample1\n",
    "df2 = len(sample2) - 1  # Degrees of freedom for sample2\n",
    "\n",
    "# Significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the critical value for the F-distribution at the given significance level (two-tailed test)\n",
    "critical_value = f.ppf(1 - alpha/2, df1, df2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Sample 1 Variance: {var1:.4f}\")\n",
    "print(f\"Sample 2 Variance: {var2:.4f}\")\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"Critical value at alpha = {alpha}: {critical_value:.4f}\")\n",
    "\n",
    "# Hypothesis testing\n",
    "if f_statistic > critical_value:\n",
    "    print(\"\\nConclusion: Reject the null hypothesis. The variances are significantly different.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Fail to reject the null hypothesis. The variances are not significantly different.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe7749-4286-469f-ac31-96ca49d524bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example Data: Test scores from three different teaching methods\n",
    "group1 = [78, 81, 85, 88, 90]  # Group 1\n",
    "group2 = [72, 75, 80, 82, 85]  # Group 2\n",
    "group3 = [92, 95, 98, 99, 100]  # Group 3\n",
    "\n",
    "# Perform the one-way ANOVA test\n",
    "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Hypothesis testing\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"\\nConclusion: Reject the null hypothesis. There is a significant difference between the group means.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Fail to reject the null hypothesis. There is no significant difference between the group means.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d98b26-4567-4df9-9437-bc996378f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example Data: Test scores from three different teaching methods\n",
    "group1 = [78, 81, 85, 88, 90]  # Group 1\n",
    "group2 = [72, 75, 80, 82, 85]  # Group 2\n",
    "group3 = [92, 95, 98, 99, 100]  # Group 3\n",
    "\n",
    "# Perform the one-way ANOVA test\n",
    "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Hypothesis testing\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"\\nConclusion: Reject the null hypothesis. There is a significant difference between the group means.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Fail to reject the null hypothesis. There is no significant difference between the group means.\")\n",
    "\n",
    "# Plot the data using a box plot for visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'], patch_artist=True)\n",
    "plt.title(\"Comparison of Test Scores Between Teaching Methods\")\n",
    "plt.xlabel(\"Teaching Methods (Groups)\")\n",
    "plt.ylabel(\"Test Scores\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b10504-2b4f-4888-ab67-70ebedda1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro, levene, bartlett\n",
    "import seaborn as sns\n",
    "\n",
    "def check_anova_assumptions(groups):\n",
    "    \"\"\"\n",
    "    Check the assumptions for one-way ANOVA: Normality, Independence, and Equal Variance.\n",
    "    \n",
    "    Parameters:\n",
    "    groups (list of lists): The data for each group.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Normality Assumption - Shapiro-Wilk Test\n",
    "    print(\"Normality Check:\")\n",
    "    for i, group in enumerate(groups, 1):\n",
    "        stat, p_value = shapiro(group)\n",
    "        print(f\"Group {i} - Shapiro-Wilk Test: Statistic = {stat:.4f}, p-value = {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"  => The group is not normally distributed (reject H0).\")\n",
    "        else:\n",
    "            print(\"  => The group is normally distributed (fail to reject H0).\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 2. Equal Variance (Homoscedasticity) - Levene's Test\n",
    "    print(\"Equal Variance Check:\")\n",
    "    stat, p_value = levene(*groups)\n",
    "    print(f\"Levene's Test: Statistic = {stat:.4f}, p-value = {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"  => The variances are significantly different (reject H0).\")\n",
    "    else:\n",
    "        print(\"  => The variances are equal (fail to reject H0).\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 3. Plotting Q-Q plots for Normality Check (optional but recommended)\n",
    "    print(\"Q-Q Plots for Normality:\")\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, group in enumerate(groups, 1):\n",
    "        plt.subplot(1, len(groups), i)\n",
    "        sns.qqplot(np.array(group), line='s')\n",
    "        plt.title(f\"Group {i}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage:\n",
    "group1 = [78, 81, 85, 88, 90]  # Group 1\n",
    "group2 = [72, 75, 80, 82, 85]  # Group 2\n",
    "group3 = [92, 95, 98, 99, 100]  # Group 3\n",
    "\n",
    "check_anova_assumptions([group1, group2, group3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a3527-a939-4409-b2f7-62943db4d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import f\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data: Crop yield as dependent variable with two factors: Fertilizer type and Watering frequency\n",
    "data = {\n",
    "    'Fertilizer': ['Organic', 'Organic', 'Organic', 'Organic', 'Chemical', 'Chemical', 'Chemical', 'Chemical',\n",
    "                   'Organic', 'Organic', 'Organic', 'Organic', 'Chemical', 'Chemical', 'Chemical', 'Chemical'],\n",
    "    'Watering': ['Low', 'Low', 'High', 'High', 'Low', 'Low', 'High', 'High',\n",
    "                 'Low', 'Low', 'High', 'High', 'Low', 'Low', 'High', 'High'],\n",
    "    'Yield': [10, 12, 15, 14, 16, 18, 22, 20, 11, 13, 17, 16, 15, 17, 19, 18]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform Two-Way ANOVA with interaction between Fertilizer and Watering\n",
    "model = ols('Yield ~ C(Fertilizer) * C(Watering)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Output the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Interpretation of results\n",
    "alpha = 0.05\n",
    "if anova_table['PR(>F)'][0] < alpha:\n",
    "    print(\"\\nFertilizer has a significant effect on Yield.\")\n",
    "else:\n",
    "    print(\"\\nFertilizer does not have a significant effect on Yield.\")\n",
    "\n",
    "if anova_table['PR(>F)'][1] < alpha:\n",
    "    print(\"Watering has a significant effect on Yield.\")\n",
    "else:\n",
    "    print(\"Watering does not have a significant effect on Yield.\")\n",
    "\n",
    "if anova_table['PR(>F)'][2] < alpha:\n",
    "    print(\"There is a significant interaction between Fertilizer and Watering.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction between Fertilizer and Watering.\")\n",
    "\n",
    "# Visualization: Interaction Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Fertilizer', y='Yield', hue='Watering', data=df)\n",
    "plt.title('Interaction Plot: Fertilizer vs Watering Frequency on Crop Yield')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b097c8-63ff-404b-b953-80f35db4ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "\n",
    "# Parameters for the F-distribution: degrees of freedom for numerator (dfn) and denominator (dfd)\n",
    "dfn = 5  # degrees of freedom for the numerator (e.g., between-group variance in ANOVA)\n",
    "dfd = 10  # degrees of freedom for the denominator (e.g., within-group variance in ANOVA)\n",
    "\n",
    "# Generate x values (range of F-statistic values)\n",
    "x = np.linspace(0, 5, 1000)\n",
    "\n",
    "# Calculate the F-distribution probability density function (PDF)\n",
    "y = f.pdf(x, dfn, dfd)\n",
    "\n",
    "# Plot the F-distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=f'F-distribution (dfn={dfn}, dfd={dfd})', color='b')\n",
    "plt.title('F-Distribution Curve')\n",
    "plt.xlabel('F-Statistic Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualizing the critical region for hypothesis testing (using a significance level of 0.05)\n",
    "alpha = 0.05\n",
    "critical_value = f.ppf(1 - alpha, dfn, dfd)\n",
    "\n",
    "# Plot the critical region\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=f'F-distribution (dfn={dfn}, dfd={dfd})', color='b')\n",
    "plt.fill_between(x, 0, y, where=(x > critical_value), color='r', alpha=0.5, label='Critical Region')\n",
    "plt.axvline(critical_value, color='r', linestyle='--', label=f'Critical Value = {critical_value:.2f}')\n",
    "plt.title('F-Distribution with Critical Region (Alpha = 0.05)')\n",
    "plt.xlabel('F-Statistic Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c5f4e-5b7d-4084-b7c1-58e3f5024fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22.  Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example Data: Scores of students in three different teaching methods\n",
    "group1 = [23, 20, 17, 24, 28, 25, 26, 22, 21]  # Teaching method 1\n",
    "group2 = [30, 32, 35, 28, 31, 33, 34, 30]      # Teaching method 2\n",
    "group3 = [17, 19, 15, 18, 14, 20, 17, 16]      # Teaching method 3\n",
    "\n",
    "# Perform One-Way ANOVA\n",
    "f_stat, p_value = f_oneway(group1, group2, group3)\n",
    "\n",
    "# Print results\n",
    "print(f\"F-statistic: {f_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nThere is a significant difference between the group means (reject H0).\")\n",
    "else:\n",
    "    print(\"\\nThere is no significant difference between the group means (fail to reject H0).\")\n",
    "\n",
    "# Visualization: Boxplots to compare group means\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=[group1, group2, group3], notch=True, patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue', color='black'), \n",
    "            whiskerprops=dict(color='black'), \n",
    "            capprops=dict(color='black'), \n",
    "            flierprops=dict(markerfacecolor='red', marker='o', markersize=5))\n",
    "\n",
    "plt.xticks([0, 1, 2], ['Teaching Method 1', 'Teaching Method 2', 'Teaching Method 3'])\n",
    "plt.title('Comparison of Group Means Using One-Way ANOVA')\n",
    "plt.ylabel('Scores')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fab32-573a-4f14-8212-e8f60e6a7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Simulate random data from a normal distribution\n",
    "np.random.seed(42)  # Set random seed for reproducibility\n",
    "\n",
    "# Group 1: Mean = 50, Standard deviation = 10, Sample size = 100\n",
    "group1 = np.random.normal(loc=50, scale=10, size=100)\n",
    "\n",
    "# Group 2: Mean = 55, Standard deviation = 10, Sample size = 100\n",
    "group2 = np.random.normal(loc=55, scale=10, size=100)\n",
    "\n",
    "# Step 2: Perform a two-sample t-test to evaluate if the means are different\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "\n",
    "# Step 3: Print results\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 4: Interpretation of results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: The means of the two groups are significantly different.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant difference between the means.\")\n",
    "\n",
    "# Step 5: Visualize the data distributions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(group1, bins=20, alpha=0.6, label='Group 1 (Mean = 50)', color='blue')\n",
    "plt.hist(group2, bins=20, alpha=0.6, label='Group 2 (Mean = 55)', color='orange')\n",
    "plt.axvline(np.mean(group1), color='blue', linestyle='dashed', linewidth=2, label=f'Group 1 Mean: {np.mean(group1):.2f}')\n",
    "plt.axvline(np.mean(group2), color='orange', linestyle='dashed', linewidth=2, label=f'Group 2 Mean: {np.mean(group2):.2f}')\n",
    "plt.legend()\n",
    "plt.title('Histogram of Simulated Data from Two Groups')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a9bb9-890f-411c-8c2f-9e3b56ab9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Step 1: Simulate data from a normal distribution\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample data: 100 samples from a normal distribution with a population variance of 25 (sigma^2 = 25)\n",
    "n = 100  # Sample size\n",
    "pop_variance = 25  # Hypothesized population variance\n",
    "sample_data = np.random.normal(loc=0, scale=np.sqrt(pop_variance), size=n)\n",
    "\n",
    "# Step 2: Calculate the sample variance\n",
    "sample_variance = np.var(sample_data, ddof=1)\n",
    "\n",
    "# Step 3: Perform the Chi-square test for variance\n",
    "# Test statistic: chi^2 = ((n - 1) * sample_variance) / hypothesized_variance\n",
    "chi_square_stat = (n - 1) * sample_variance / pop_variance\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Step 4: Find the critical values for a two-tailed test at alpha = 0.05\n",
    "alpha = 0.05\n",
    "lower_critical_value = chi2.ppf(alpha / 2, df)\n",
    "upper_critical_value = chi2.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Step 5: Interpret the results\n",
    "print(f\"Sample Variance: {sample_variance:.4f}\")\n",
    "print(f\"Chi-square Statistic: {chi_square_stat:.4f}\")\n",
    "print(f\"Critical Values: Lower = {lower_critical_value:.4f}, Upper = {upper_critical_value:.4f}\")\n",
    "\n",
    "# Step 6: Decision rule\n",
    "if chi_square_stat < lower_critical_value or chi_square_stat > upper_critical_value:\n",
    "    print(\"\\nReject the null hypothesis: The population variance is different from the hypothesized variance.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: The population variance is equal to the hypothesized variance.\")\n",
    "\n",
    "# Visualization: Plot the Chi-square distribution with critical regions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 2 * chi_square_stat, 1000)\n",
    "y = chi2.pdf(x, df)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=f'Chi-square Distribution (df={df})', color='b')\n",
    "plt.fill_between(x, 0, y, where=(x < lower_critical_value), color='red', alpha=0.3, label='Lower Critical Region')\n",
    "plt.fill_between(x, 0, y, where=(x > upper_critical_value), color='red', alpha=0.3, label='Upper Critical Region')\n",
    "plt.axvline(chi_square_stat, color='black', linestyle='--', label=f'Test Statistic = {chi_square_stat:.2f}')\n",
    "plt.title('Chi-square Distribution and Critical Regions')\n",
    "plt.xlabel('Chi-square Statistic')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda1101-fa20-4c2c-a531-1a5fadd3a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Step 1: Simulate data for two groups (successes and sample sizes)\n",
    "# Group 1: 60 successes out of 200 trials\n",
    "# Group 2: 45 successes out of 180 trials\n",
    "\n",
    "x1 = 60  # Number of successes in group 1\n",
    "n1 = 200  # Sample size for group 1\n",
    "\n",
    "x2 = 45  # Number of successes in group 2\n",
    "n2 = 180  # Sample size for group 2\n",
    "\n",
    "# Step 2: Calculate sample proportions\n",
    "p1 = x1 / n1\n",
    "p2 = x2 / n2\n",
    "\n",
    "# Step 3: Calculate the combined proportion\n",
    "P = (x1 + x2) / (n1 + n2)\n",
    "\n",
    "# Step 4: Calculate the Z-statistic\n",
    "z_stat = (p1 - p2) / math.sqrt(P * (1 - P) * (1 / n1 + 1 / n2))\n",
    "\n",
    "# Step 5: Calculate the p-value (two-tailed test)\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))  # Two-tailed test\n",
    "\n",
    "# Step 6: Print the results\n",
    "print(f\"Proportion of successes in Group 1: {p1:.4f}\")\n",
    "print(f\"Proportion of successes in Group 2: {p2:.4f}\")\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 7: Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: The proportions are significantly different.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: The proportions are not significantly different.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e4eeb-5c15-4128-99c7-2e2e0ea9aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26. Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Simulate data for two groups with different variances\n",
    "np.random.seed(42)\n",
    "\n",
    "# Group 1: 100 samples with a variance of 25\n",
    "group1 = np.random.normal(loc=0, scale=5, size=100)\n",
    "\n",
    "# Group 2: 100 samples with a variance of 50\n",
    "group2 = np.random.normal(loc=0, scale=np.sqrt(50), size=100)\n",
    "\n",
    "# Step 2: Calculate sample variances\n",
    "var1 = np.var(group1, ddof=1)\n",
    "var2 = np.var(group2, ddof=1)\n",
    "\n",
    "# Step 3: Perform the F-test\n",
    "# F-statistic: var1 / var2\n",
    "f_statistic = var1 / var2 if var1 > var2 else var2 / var1  # Ensure the larger variance is in the numerator\n",
    "\n",
    "# Degrees of freedom\n",
    "df1 = len(group1) - 1\n",
    "df2 = len(group2) - 1\n",
    "\n",
    "# Step 4: Calculate the p-value for the F-test\n",
    "p_value = 2 * min(f.cdf(f_statistic, df1, df2), 1 - f.cdf(f_statistic, df1, df2))\n",
    "\n",
    "# Step 5: Print results\n",
    "print(f\"Variance of Group 1: {var1:.4f}\")\n",
    "print(f\"Variance of Group 2: {var2:.4f}\")\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 6: Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: The variances are significantly different.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: The variances are not significantly different.\")\n",
    "\n",
    "# Step 7: Visualization of the F-distribution and test statistic\n",
    "x = np.linspace(0, 4, 1000)\n",
    "y = f.pdf(x, df1, df2)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})', color='b')\n",
    "plt.fill_between(x, 0, y, where=(x >= f_statistic), color='red', alpha=0.3, label='Critical Region')\n",
    "plt.axvline(f_statistic, color='black', linestyle='--', label=f'F-statistic = {f_statistic:.4f}')\n",
    "plt.title('F-distribution and Critical Region')\n",
    "plt.xlabel('F-statistic')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9aedb-f1bb-4253-a7cc-721c4b3adc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Simulate observed data\n",
    "# Suppose we are testing if the outcomes of a 6-sided die are fair.\n",
    "# We simulate observed frequencies (after rolling a die 60 times)\n",
    "observed = np.array([12, 8, 10, 9, 11, 10])  # Observed frequencies for sides 1 to 6\n",
    "\n",
    "# Step 2: Define expected frequencies for a fair die (each outcome should be 1/6 of the total rolls)\n",
    "total_rolls = sum(observed)\n",
    "expected = np.array([total_rolls / 6] * 6)\n",
    "\n",
    "# Step 3: Perform the Chi-square test for goodness of fit\n",
    "chi2_stat, p_value = chisquare(observed, expected)\n",
    "\n",
    "# Step 4: Print results\n",
    "print(f\"Observed frequencies: {observed}\")\n",
    "print(f\"Expected frequencies: {expected}\")\n",
    "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 5: Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: The die is not fair.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: The die is fair.\")\n",
    "\n",
    "# Step 6: Visualization\n",
    "# Plot the observed and expected frequencies for comparison\n",
    "categories = [1, 2, 3, 4, 5, 6]\n",
    "x = np.arange(len(categories))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(x - 0.2, observed, 0.4, label='Observed', color='skyblue')\n",
    "plt.bar(x + 0.2, expected, 0.4, label='Expected', color='orange')\n",
    "\n",
    "plt.xticks(x, categories)\n",
    "plt.xlabel('Die Sides')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Observed vs Expected Frequencies for a 6-Sided Die')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
