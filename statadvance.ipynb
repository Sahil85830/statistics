{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92a9c1-61b2-4912-95aa-aa9f89d51871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.  What is hypothesis testing in statistics?\n",
    "''' Hypothesis testing in statistics is a method used to make decisions or inferences about a population based on a sample. It involves the following steps:  \n",
    "\n",
    "1. **Formulating Hypotheses**:  \n",
    "   - **Null Hypothesis (H₀)**: Assumes no effect or no difference (e.g., \"The average car price is the same across all regions\").  \n",
    "   - **Alternative Hypothesis (H₁ or Ha)**: Represents a claim to be tested (e.g., \"The average car price differs across regions\").  \n",
    "\n",
    "2. **Selecting a Significance Level (α)**:  \n",
    "   - Common values are 0.05 or 0.01, representing the probability of rejecting H₀ when it is true.  \n",
    "\n",
    "3. **Choosing a Test Statistic**:  \n",
    "   - Depends on data type and hypothesis (e.g., t-test, chi-square test, ANOVA).  \n",
    "\n",
    "4. **Computing the p-value**:  \n",
    "   - The probability of obtaining results at least as extreme as observed, assuming H₀ is true.  \n",
    "\n",
    "5. **Making a Decision**:  \n",
    "   - If **p-value ≤ α**, reject H₀ (evidence supports H₁).  \n",
    "   - If **p-value > α**, fail to reject H₀ (not enough evidence to support H₁).  \n",
    "\n",
    "It helps in making data-driven conclusions in various fields like medicine, business, and social sciences. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13769c4-5039-4b53-b926-c214ca801b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
    "'''The **Null Hypothesis (H₀)** and **Alternative Hypothesis (H₁ or Ha)** are fundamental concepts in hypothesis testing:  \n",
    "\n",
    "1. **Null Hypothesis (H₀)**:  \n",
    "   - Represents the default assumption or status quo.  \n",
    "   - Assumes no effect, no difference, or no relationship in the population.  \n",
    "   - Example: *\"There is no difference in the average selling price of cars across different regions.\"*  \n",
    "\n",
    "2. **Alternative Hypothesis (H₁ or Ha)**:  \n",
    "   - Represents what we are trying to prove.  \n",
    "   - Suggests there is an effect, difference, or relationship.  \n",
    "   - Example: *\"The average selling price of cars differs across different regions.\"*  \n",
    "\n",
    "### **Key Difference**:  \n",
    "- The **null hypothesis** is assumed true unless there is strong statistical evidence against it.  \n",
    "- The **alternative hypothesis** is what we aim to support with data.  \n",
    "- If the **p-value ≤ significance level (α)**, we reject H₀ in favor of H₁. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa7c81-32e8-46e0-aa5a-0106c74f24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. What is the significance level in hypothesis testing, and why is it important?\n",
    "'''The **significance level (α)** in hypothesis testing is the probability of rejecting the **null hypothesis (H₀)** when it is actually true (Type I error). It sets the threshold for statistical significance.  \n",
    "\n",
    "### **Common Values of α:**  \n",
    "- **0.05 (5%)** – Most commonly used.  \n",
    "- **0.01 (1%)** – Used for stricter testing (e.g., medical trials).  \n",
    "- **0.10 (10%)** – Sometimes used in exploratory studies.  \n",
    "\n",
    "### **Why is it Important?**  \n",
    "1. **Controls Type I Error**: Reduces the chance of falsely rejecting H₀.  \n",
    "2. **Determines Decision Criteria**: If **p-value ≤ α**, reject H₀; otherwise, fail to reject H₀.  \n",
    "3. **Balances Accuracy**: A lower α reduces false positives but increases false negatives (Type II error).  \n",
    "\n",
    "Choosing α depends on the study context—higher stakes require lower α. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485bfe2-97bb-4942-a920-b5fe4b865a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What does a P-value represent in hypothesis testing?\n",
    "'''The **P-value** in hypothesis testing represents the probability of obtaining results at least as extreme as the observed data, assuming the **null hypothesis (H₀)** is true.  \n",
    "\n",
    "### **Interpretation of P-value:**  \n",
    "- **Low P-value (≤ α, e.g., 0.05)** → Strong evidence **against** H₀ → **Reject H₀** (supports H₁).  \n",
    "- **High P-value (> α)** → Weak evidence against H₀ → **Fail to reject H₀** (insufficient support for H₁).  \n",
    "\n",
    "### **Example:**  \n",
    "If a test yields **P = 0.03** with **α = 0.05**, we reject H₀, suggesting a significant effect or difference exists.  \n",
    "\n",
    "### **Why is it Important?**  \n",
    "- Helps determine statistical significance.  \n",
    "- Provides a measure of strength of evidence against H₀.  \n",
    "- Guides decision-making in research and experiments. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17610afe-3d9f-4498-845f-4a65c0d3dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. How do you interpret the P-value in hypothesis testing?\n",
    "'''### **Interpreting the P-value in Hypothesis Testing**  \n",
    "\n",
    "The **P-value** indicates the probability of obtaining results as extreme as the observed data, assuming the **null hypothesis (H₀)** is true.  \n",
    "\n",
    "### **Interpretation Guidelines:**  \n",
    "- **P ≤ α (e.g., 0.05)** → **Reject H₀** → Strong evidence against H₀ → Supports the alternative hypothesis (**H₁**).  \n",
    "- **P > α** → **Fail to reject H₀** → Insufficient evidence to support H₁ → The observed result could be due to chance.  \n",
    "\n",
    "### **Example Interpretation:**  \n",
    "- **P = 0.02, α = 0.05** → Reject H₀ → Significant result → Suggests an actual effect.  \n",
    "- **P = 0.08, α = 0.05** → Fail to reject H₀ → Not statistically significant → No strong evidence of an effect.  \n",
    "\n",
    "The **smaller the P-value**, the stronger the evidence against H₀. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bc0b0-bb14-4dda-bf8d-09245aff3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
    "'''### **Type 1 and Type 2 Errors in Hypothesis Testing**  \n",
    "\n",
    "#### **1. Type 1 Error (False Positive)**  \n",
    "- Occurs when we **reject the null hypothesis (H₀) when it is actually true**.  \n",
    "- Represented by the **significance level (α)** (e.g., α = 0.05 means a 5% chance of making this error).  \n",
    "- **Example**: A test incorrectly detects a disease in a healthy person.  \n",
    "\n",
    "#### **2. Type 2 Error (False Negative)**  \n",
    "- Occurs when we **fail to reject the null hypothesis (H₀) when it is actually false**.  \n",
    "- Represented by **β (beta)**, where **power = 1 - β** (higher power reduces Type 2 error).  \n",
    "- **Example**: A test fails to detect a disease in a sick person.  \n",
    "\n",
    "### **Key Difference:**  \n",
    "- **Type 1 Error:** Detects an effect that doesn’t exist (false alarm).  \n",
    "- **Type 2 Error:** Misses a real effect (failure to detect).  \n",
    "\n",
    "Balancing **α** and **β** is crucial—lowering one often increases the other. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfd75e-f88a-4119-8b43-ced524ed5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
    "'''### **One-Tailed vs. Two-Tailed Test in Hypothesis Testing**  \n",
    "\n",
    "#### **1. One-Tailed Test (Directional Test)**  \n",
    "- Tests for an effect in **only one direction** (greater or less than).  \n",
    "- **Null Hypothesis (H₀)**: No difference or effect.  \n",
    "- **Alternative Hypothesis (H₁)**: Specifies a direction (e.g., \"Car prices in Region A are higher than in Region B\").  \n",
    "- **Example**:  \n",
    "  - H₀: The average fuel efficiency of a new car model is **≤ 20 km/l**.  \n",
    "  - H₁: The average fuel efficiency is **> 20 km/l**.  \n",
    "- **Used When**: Prior knowledge or theory suggests a specific direction.  \n",
    "\n",
    "#### **2. Two-Tailed Test (Non-Directional Test)**  \n",
    "- Tests for an effect in **both directions** (higher or lower).  \n",
    "- **Null Hypothesis (H₀)**: No difference or effect.  \n",
    "- **Alternative Hypothesis (H₁)**: Any difference, regardless of direction (e.g., \"Car prices in Region A are different from Region B\").  \n",
    "- **Example**:  \n",
    "  - H₀: The average fuel efficiency is **20 km/l**.  \n",
    "  - H₁: The average fuel efficiency is **not 20 km/l**.  \n",
    "- **Used When**: No prior expectation of the effect’s direction.  \n",
    "\n",
    "### **Key Difference:**  \n",
    "- **One-Tailed**: Tests for an increase **or** decrease.  \n",
    "- **Two-Tailed**: Tests for **any** difference, in either direction.  \n",
    "\n",
    "Choosing the right test depends on the research question! '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf99200-69cf-45fe-8bd2-35d3fc2a173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.  What is the Z-test, and when is it used in hypothesis testing?\n",
    "'''### **Z-Test in Hypothesis Testing**  \n",
    "\n",
    "A **Z-test** is a statistical test used to determine whether there is a significant difference between sample and population means or between two samples when the population variance is known. It follows the **standard normal distribution (Z-distribution).**  \n",
    "\n",
    "### **When is the Z-Test Used?**  \n",
    "1. **Large Sample Size (n ≥ 30)**: Central Limit Theorem ensures normality.  \n",
    "2. **Known Population Variance (σ²)**: Unlike the t-test, where variance is estimated.  \n",
    "3. **Normally Distributed Data**: Especially for small samples.  \n",
    "\n",
    "### **Types of Z-Tests:**  \n",
    "1. **One-Sample Z-Test**: Compares a sample mean to a known population mean.  \n",
    "2. **Two-Sample Z-Test**: Compares means of two independent samples.  \n",
    "3. **Proportion Z-Test**: Compares proportions of two groups.  \n",
    "\n",
    "### **Example:**  \n",
    "A car manufacturer claims its cars have an average mileage of **15 km/l**. A sample of 50 cars shows an average of **14.5 km/l** with a known population standard deviation of **1.2 km/l**. A Z-test can check if the difference is statistically significant.  \n",
    " **Z-test is best for large samples with known variance!** '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166118da-08f4-478b-95cb-6352da4b20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
    "''' Z score X minus mu divided by sigma  \n",
    "\n",
    "For a sample mean Z equals X bar minus mu divided by sigma divided by square root of n  \n",
    "\n",
    "X is individual data point  \n",
    "X bar is sample mean  \n",
    "Mu is population mean  \n",
    "Sigma is population standard deviation  \n",
    "n is sample size  \n",
    "\n",
    "Higher absolute Z score means data point is farther from the mean  \n",
    "Z greater than zero value is above the mean  \n",
    "Z less than zero value is below the mean  \n",
    "Z equals zero value is exactly the mean  \n",
    "\n",
    "In hypothesis testing compare Z score with critical values example plus minus one point nine six for ninety five percent confidence  \n",
    "\n",
    "Example calculation  \n",
    "Population mean is twenty five thousand  \n",
    "Sample mean is twenty six thousand five hundred  \n",
    "Sample size is forty  \n",
    "Population standard deviation is three thousand  \n",
    "\n",
    "Z equals twenty six thousand five hundred minus twenty five thousand divided by three thousand divided by square root of forty  \n",
    "\n",
    "Z equals one thousand five hundred divided by four hundred seventy four point three four  \n",
    "\n",
    "Z approximately equals three point one six  \n",
    "\n",
    "Since Z equals three point one six exceeds one point nine six for ninety five percent confidence we reject the null hypothesis suggesting a significant difference.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7fc21-aa46-4d78-a28e-745c374d0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
    "'''T distribution is a probability distribution used in hypothesis testing when the sample size is small or the population standard deviation is unknown  \n",
    "\n",
    "Use T distribution instead of normal distribution when  \n",
    "Sample size is less than thirty  \n",
    "Population standard deviation is unknown  \n",
    "Data is approximately normally distributed  \n",
    "\n",
    "T distribution has heavier tails than normal distribution meaning more variability in smaller samples  \n",
    "\n",
    "As sample size increases T distribution approaches normal distribution.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bc154-6b4a-4a6b-92dd-a6611735e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.What is the difference between a Z-test and a T-test?\n",
    "'''Z test is used when sample size is large and population standard deviation is known  \n",
    "\n",
    "T test is used when sample size is small and population standard deviation is unknown  \n",
    "\n",
    "Z test follows normal distribution while T test follows T distribution with heavier tails  \n",
    "\n",
    "T test is more appropriate for small samples since it accounts for additional variability.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002c045-cdf3-45a0-8900-c1783079824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. What is the T-test, and how is it used in hypothesis testing?'''\n",
    "'''T test is a statistical test used to compare means of a sample and a population or two samples when the population standard deviation is unknown.  \n",
    "\n",
    "Types of T test, One sample T test compares sample mean to a known population mean. Independent two sample T test compares means of two independent groups. Paired T test compares means of the same group before and after a treatment.  \n",
    "\n",
    "Formula for T test, T equals X bar minus mu divided by S divided by square root of n.  \n",
    "\n",
    "Where, X bar is sample mean, Mu is population mean, S is sample standard deviation, n is sample size.  \n",
    "\n",
    "Compare T value with critical T value from T table based on significance level and degrees of freedom to determine statistical significance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8116e-df21-4ed9-899a-60c72e4ec152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
    "'''Z test and T test are both used to compare sample means and test hypotheses about population parameters.  \n",
    "\n",
    "Z test is used when the sample size is large and population standard deviation is known. T test is used when the sample size is small and population standard deviation is unknown.  \n",
    "\n",
    "Both tests assume data is approximately normally distributed. T test accounts for more variability in small samples due to its heavier tails.  \n",
    "\n",
    "As sample size increases, T distribution approaches normal distribution, making Z test and T test results similar for large samples.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7972fc8-e5d1-4091-9b33-862d14816fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. What is a confidence interval, and how is it used to interpret statistical results?\n",
    "'''A confidence interval is a range of values used to estimate a population parameter with a certain level of confidence.  \n",
    "\n",
    "It is calculated as, Confidence interval equals sample statistic plus minus critical value multiplied by standard error.  \n",
    "\n",
    "Where, Sample statistic is sample mean or proportion. Critical value is based on confidence level from Z or T table. Standard error is standard deviation divided by square root of sample size.  \n",
    "\n",
    "A confidence interval of 95 percent means that if the same study is repeated many times, 95 percent of the calculated intervals will contain the true population parameter.  \n",
    "\n",
    "A wider confidence interval indicates more uncertainty, while a narrower interval suggests higher precision.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f650f-1c7c-470a-b993-98ad432c96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. What is the margin of error, and how does it affect the confidence interval?\n",
    "'''Margin of error is the maximum expected difference between the sample statistic and the true population parameter.  \n",
    "\n",
    "It is calculated as, Margin of error equals critical value multiplied by standard error.  \n",
    "\n",
    "Where, Critical value is from Z or T table based on confidence level. Standard error is standard deviation divided by square root of sample size.  \n",
    "\n",
    "A larger margin of error results in a wider confidence interval, indicating more uncertainty. A smaller margin of error results in a narrower confidence interval, indicating higher precision.  \n",
    "\n",
    "Margin of error decreases with a larger sample size and lower variability in data.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370749ae-9c8d-4ba6-ad73-6b014acf31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
    "'''Bayes' Theorem is used to update probabilities based on new evidence.  \n",
    "\n",
    "Formula, Posterior probability equals Prior probability multiplied by Likelihood divided by Evidence.  \n",
    "\n",
    "Where, Prior probability is initial belief about an event. Likelihood is probability of evidence given the event. Evidence is total probability of observed data.  \n",
    "\n",
    "Significance, It helps in decision-making by updating probabilities with new information. It is widely used in machine learning, medical diagnosis, spam filtering, and risk assessment. It provides a probabilistic framework for inference.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b69fd-74d5-4d2b-b27f-e4513c368cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. What is the Chi-square distribution, and when is it used?\n",
    "'''Chi square distribution is a probability distribution used in statistical tests involving categorical data and variance estimation.  \n",
    "\n",
    "It is used when testing the independence of two categorical variables in a contingency table, called the Chi square test for independence. It is also used to test if an observed frequency distribution matches an expected distribution, called the Chi square goodness of fit test. It is used in variance estimation for normally distributed populations.  \n",
    "\n",
    "Chi square distribution is always positive and skewed right, but it becomes more symmetric as degrees of freedom increase.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106a956-22a4-461b-b087-b34c260baf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. What is the Chi-square goodness of fit test, and how is it applied?\n",
    "'''Chi square goodness of fit test checks if an observed frequency distribution matches an expected distribution.  \n",
    "\n",
    "Formula, Chi square equals sum of observed frequency minus expected frequency squared divided by expected frequency.  \n",
    "\n",
    "Where, Observed frequency is actual data count, Expected frequency is theoretical count based on assumption.  \n",
    "\n",
    "Steps, Define null hypothesis stating that observed and expected distributions are the same. Calculate expected frequencies based on assumption. Compute Chi square statistic using the formula. Compare Chi square value with critical value from Chi square table based on degrees of freedom and significance level. Reject null hypothesis if Chi square value is greater than critical value.  \n",
    "\n",
    "Application, Used in genetics, market research, and quality control to test distribution assumptions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65962a-6042-4957-9aa9-d2e6ddc811b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. What is the F-distribution, and when is it used in hypothesis testing?\n",
    "'''F distribution is a probability distribution used to compare variances of two populations and in analysis of variance ANOVA.  \n",
    "\n",
    "It is used when testing if two population variances are equal, called the F test for variance comparison. It is also used in ANOVA to compare means of multiple groups by analyzing variance. It is applied in regression analysis to test overall model significance.  \n",
    "\n",
    "F distribution is always positive and right skewed. Its shape depends on two degrees of freedom, one for numerator and one for denominator.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70cc57-01f3-412f-90c9-3cbeee6c35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. What is an ANOVA test, and what are its assumptions?\n",
    "'''ANOVA test, Analysis of Variance, is a statistical test used to compare means of three or more groups to determine if there is a significant difference.  \n",
    "\n",
    "Assumptions, The data follows a normal distribution within each group. The variances of all groups are equal, called homogeneity of variance. The observations are independent within and across groups.  \n",
    "\n",
    "If assumptions hold, ANOVA determines if at least one group mean is different, but it does not specify which group differs. Post hoc tests like Tukey test are used for pairwise comparisons.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81f435-f230-46ad-bbf6-52b97ff2c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. What are the different types of ANOVA tests?\n",
    "'''The main types of ANOVA (Analysis of Variance) tests are:\n",
    "\n",
    "1. **One-Way ANOVA**: Used to compare means across more than two groups based on one independent variable.\n",
    "\n",
    "2. **Two-Way ANOVA**: Assesses the effect of two independent variables on a dependent variable, and can also examine interaction effects between the two factors.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Used when the same subjects are measured multiple times under different conditions.\n",
    "\n",
    "4. **Multivariate Analysis of Variance (MANOVA)**: Extends ANOVA to multiple dependent variables.\n",
    "\n",
    "5. **Analysis of Covariance (ANCOVA)**: Combines ANOVA and regression to examine the effect of one or more categorical independent variables on a continuous dependent variable, adjusting for covariates.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba37ca5-f298-4197-804c-0094b3cd78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22. What is the F-test, and how does it relate to hypothesis testing?\n",
    "'''The **F-test** is used to compare two variances or to test the overall significance of a model. In hypothesis testing, it is commonly used in the context of **ANOVA** and **regression analysis**.\n",
    "\n",
    "1. **In ANOVA**: The F-test compares the variance between group means to the variance within the groups. If the ratio (F-statistic) is large, it suggests that the means of the groups are significantly different.\n",
    "\n",
    "2. **In Regression**: The F-test evaluates whether at least one of the predictor variables is significantly related to the dependent variable by testing the null hypothesis that all regression coefficients are zero.\n",
    "\n",
    "The F-test follows this process:\n",
    "- **Null hypothesis (H₀)**: Assumes no effect or no difference (e.g., no relationship between variables).\n",
    "- **Alternative hypothesis (H₁)**: Suggests a significant effect or difference.\n",
    "\n",
    "A large F-statistic leads to rejecting the null hypothesis, indicating a significant difference or effect.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96562e-d945-43ec-973a-cf702f48abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                        #PRACTICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6c17f-98f0-4a36-96b3-08e2b110df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "sample_data = [55, 58, 60, 62, 54, 59, 61, 63, 64, 58]  # Sample of observations\n",
    "population_mean = 60  # Known population mean\n",
    "population_std = 5  # Known population standard deviation\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Compute the Z-statistic\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Compute the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d52db6-2548-457a-b07f-3531b0e47b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulating random data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 10  # Known population standard deviation\n",
    "sample_size = 100  # Sample size\n",
    "\n",
    "# Generate random data from a normal distribution with the known population parameters\n",
    "sample_data = np.random.normal(loc=population_mean, scale=population_std, size=sample_size)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Perform Z-test (one-sample)\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Calculate the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee133016-7e0c-49ed-8a59-44845127f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "sample_data = [48, 50, 52, 49, 51, 50, 48, 50, 49, 52]  # Sample of observations\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 5  # Known population standard deviation\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Compute the Z-statistic\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Compute the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9303fab-5c3e-41f3-9c5d-3a8f45c9b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "sample_data = [48, 50, 52, 49, 51, 50, 48, 50, 49, 52]  # Sample of observations\n",
    "population_mean = 50  # Known population mean\n",
    "population_std = 5  # Known population standard deviation\n",
    "sample_size = len(sample_data)\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "\n",
    "# Compute the Z-statistic\n",
    "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Compute the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Z-Statistic: {z_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Visualization of the normal distribution and decision regions\n",
    "alpha = 0.05  # Significance level\n",
    "z_critical = stats.norm.ppf(1 - alpha / 2)  # Critical value for two-tailed test\n",
    "\n",
    "# Create a range of values for plotting the standard normal distribution\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = stats.norm.pdf(x)\n",
    "\n",
    "# Plot the normal distribution curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, label=\"Standard Normal Distribution\", color='b')\n",
    "\n",
    "# Shade the critical regions (alpha/2 on both tails)\n",
    "plt.fill_between(x, y, 0, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.5, label='Critical Region')\n",
    "\n",
    "# Mark the Z-statistic on the plot\n",
    "plt.axvline(z_statistic, color='green', linestyle='dashed', label=f\"Z-Statistic: {z_statistic:.2f}\")\n",
    "plt.axvline(-z_statistic, color='green', linestyle='dashed')\n",
    "\n",
    "# Highlight the critical Z values (± z_critical)\n",
    "plt.axvline(z_critical, color='orange', linestyle='dashed', label=f\"Critical Z: ±{z_critical:.2f}\")\n",
    "plt.axvline(-z_critical, color='orange', linestyle='dashed')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Two-Tailed Z-Test: Decision Region Visualization\")\n",
    "plt.xlabel(\"Z-Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f01c6a-c933-4771-b21a-dd2aeafe3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Function to calculate and visualize Type I and Type II errors\n",
    "def visualize_errors(sample_size, population_mean, population_std, alternative_mean, alpha=0.05):\n",
    "    # Generate values for the standard normal distribution under the null hypothesis\n",
    "    x = np.linspace(population_mean - 4 * population_std, population_mean + 4 * population_std, 1000)\n",
    "    null_dist = stats.norm.pdf(x, population_mean, population_std / np.sqrt(sample_size))  # Under null hypothesis\n",
    "\n",
    "    # Generate values for the sampling distribution under the alternative hypothesis\n",
    "    alt_dist = stats.norm.pdf(x, alternative_mean, population_std / np.sqrt(sample_size))  # Under alternative hypothesis\n",
    "\n",
    "    # Critical value for two-tailed test\n",
    "    z_critical = stats.norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    # Type I Error (rejecting the null when it's true) is the area in the rejection region under the null hypothesis\n",
    "    type_1_error_area = stats.norm.cdf(-z_critical, population_mean, population_std / np.sqrt(sample_size)) + \\\n",
    "                         (1 - stats.norm.cdf(z_critical, population_mean, population_std / np.sqrt(sample_size)))\n",
    "\n",
    "    # Type II Error (failing to reject the null when the alternative is true) is the area under the alternative curve\n",
    "    # that does not fall into the rejection region\n",
    "    type_2_error_area = stats.norm.cdf(z_critical, alternative_mean, population_std / np.sqrt(sample_size)) - \\\n",
    "                        stats.norm.cdf(-z_critical, alternative_mean, population_std / np.sqrt(sample_size))\n",
    "\n",
    "    # Plotting the distributions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the null distribution\n",
    "    plt.plot(x, null_dist, label='Null Hypothesis Distribution (H₀)', color='blue')\n",
    "    \n",
    "    # Plot the alternative distribution\n",
    "    plt.plot(x, alt_dist, label='Alternative Hypothesis Distribution (H₁)', color='green')\n",
    "\n",
    "    # Shade the critical regions for Type I error\n",
    "    plt.fill_between(x, null_dist, 0, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.5, label='Critical Region (Rejection Region)')\n",
    "    \n",
    "    # Shade the Type II error area under the alternative distribution (failure to reject H₀)\n",
    "    plt.fill_between(x, alt_dist, 0, where=(x > -z_critical) & (x < z_critical), color='yellow', alpha=0.5, label='Type II Error Region')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f\"Visualization of Type I and Type II Errors\\nType I Error Area = {type_1_error_area:.4f}, Type II Error Area = {type_2_error_area:.4f}\")\n",
    "    plt.xlabel('Z-Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Return the error areas\n",
    "    return type_1_error_area, type_2_error_area\n",
    "\n",
    "# Example usage\n",
    "sample_size = 30  # Sample size\n",
    "population_mean = 50  # Null hypothesis population mean\n",
    "population_std = 5  # Population standard deviation\n",
    "alternative_mean = 52  # Alternative hypothesis mean (effect size)\n",
    "\n",
    "# Call the function and visualize the errors\n",
    "type_1_error, type_2_error = visualize_errors(sample_size, population_mean, population_std, alternative_mean)\n",
    "\n",
    "print(f\"Type I Error (α): {type_1_error:.4f}\")\n",
    "print(f\"Type II Error (β): {type_2_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036f203-4abe-4d96-8487-babe2c883532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Write a Python program to perform an independent T-test and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for two groups\n",
    "group1 = [23, 25, 29, 31, 22, 27, 30, 29, 28, 26]  # Group 1 data\n",
    "group2 = [34, 36, 33, 38, 35, 37, 39, 32, 33, 34]  # Group 2 data\n",
    "\n",
    "# Perform the independent T-test\n",
    "t_statistic, p_value = stats.ttest_ind(group1, group2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the two groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two groups.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122f2a7-6506-479c-ac28-3fb46eca28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.  Perform a paired sample T-test using Python and visualize the comparison results.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Example data: Measurements before and after some intervention (paired samples)\n",
    "before = [85, 88, 90, 87, 86, 91, 89, 92, 85, 88]  # Measurements before intervention\n",
    "after = [82, 84, 89, 85, 83, 88, 87, 90, 83, 86]   # Measurements after intervention\n",
    "\n",
    "# Perform the paired sample T-test\n",
    "t_statistic, p_value = stats.ttest_rel(before, after)\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between before and after intervention.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between before and after intervention.\")\n",
    "\n",
    "# Visualization: Plotting the before and after values\n",
    "x = np.arange(len(before))\n",
    "\n",
    "# Plotting before and after values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, before, 'o-', label=\"Before Intervention\", color='blue')\n",
    "plt.plot(x, after, 'o-', label=\"After Intervention\", color='green')\n",
    "\n",
    "# Adding a horizontal line at y=0 to emphasize the differences\n",
    "plt.axhline(0, color='black', linewidth=1)\n",
    "\n",
    "# Highlight the differences\n",
    "for i in range(len(before)):\n",
    "    plt.plot([x[i], x[i]], [before[i], after[i]], color='gray', alpha=0.7)\n",
    "\n",
    "plt.title(\"Paired Sample T-Test: Before vs After Intervention\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
